{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkmZkTv6WW7s"
      },
      "source": [
        "##### Copyright 2023 Google LLC. SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I36DZu2LWZkE"
      },
      "source": [
        "Copyright 2023 Google LLC. SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHsncwrPOxZt"
      },
      "source": [
        "# **Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners** Demo\n",
        "\n",
        "[KnowNo](https://robot-help.github.io) is a framework for measuring and aligning the uncertainty of LLM-based planners, such that they know when they don't know, and ask for help when needed. KnowNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help.\n",
        "\n",
        "This colab shows the very basics of constructing the prediction set (possible actions in a scenario) in the Mobile Manipulation setting. The left side of the figure belore shows a sample scenario.\n",
        "\n",
        "<img src=\"https://robot-help.github.io/img/robot-help-teaser.png\" height=\"280px\">\n",
        "\n",
        "Note:\n",
        "* Instead of setting up the scenario distribution here, we will load a dataset sampled from a pre-defined scenario distribution involving the mobile robot, the same used in the experiments. We will also use calibration results already computed with the distribution.\n",
        "* We use [GPT-3.5](https://arxiv.org/abs/2005.14165) (text-davinci-003) as the language model here.\n",
        "* We focus on the planning part; we do not consider object detection or low-level action execution here.\n",
        "\n",
        "Disclaimer: We fine the GPT3.5 model significantly underperforms [PaLM2-L](https://ai.google/discover/palm2/) model used in our experiments, largely due to its bias towards option C and D over option A and B in multiple choice question answering. We also find such bias dependent on the context, so adjusting bias for certain options in the API call does not help significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3wvRmWYVPLA"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "DpR4dgevMMsa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (1.3.7)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (4.66.1)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (2.5.2)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
            "Requirement already satisfied: stable-baselines3[extra] in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (2.2.1)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (2.1.1)\n",
            "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (4.8.1.78)\n",
            "Requirement already satisfied: pygame in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (2.15.1)\n",
            "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (4.66.1)\n",
            "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (13.7.0)\n",
            "Requirement already satisfied: shimmy~=1.3.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from stable-baselines3[extra]) (10.1.0)\n",
            "Requirement already satisfied: autorom~=0.6.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.31.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.1)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.23.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (68.0.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: importlib-resources in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\envs\\knowno\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#@markdown A few imports\n",
        "!pip install openai tqdm\n",
        "!pip install stable-baselines3[extra]\n",
        "\n",
        "import openai\n",
        "import signal\n",
        "import tqdm.notebook as tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set OpenAI API key.\n",
        "# openai.api_key = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import openai\n",
        "openai_api_key = \"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\"\n",
        "client = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "cellView": "form",
        "id": "SZF1j4s_VRdq"
      },
      "outputs": [],
      "source": [
        "#@markdown **LLM API call:** completion and scoring optionally\n",
        "import signal\n",
        "class timeout:\n",
        "    def __init__(self, seconds=1, error_message='Timeout'):\n",
        "        self.seconds = seconds\n",
        "        self.error_message = error_message\n",
        "\n",
        "    def handle_timeout(self, signum, frame):\n",
        "        raise TimeoutError(self.error_message)\n",
        "\n",
        "    def __enter__(self):\n",
        "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
        "        signal.alarm(self.seconds)\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        signal.alarm(0)\n",
        "\n",
        "# OpenAI only supports up to five tokens (logprobs argument) for getting the likelihood.\n",
        "# Thus we use the logit_bias argument to force LLM only consdering the five option\n",
        "# tokens: A, B, C, D, E\n",
        "def lm(prompt,\n",
        "       max_tokens=256,\n",
        "       temperature=0,\n",
        "       logprobs=None,\n",
        "       stop_seq=None,\n",
        "       logit_bias={\n",
        "          362: 100.0,   #  A (with space at front)\n",
        "          426: 100.0,   #  B (with space at front)\n",
        "          356: 100.0,   #  C (with space at front)\n",
        "          423: 100.0,   #  D (with space at front)\n",
        "          469: 100.0,   #  E (with space at front)\n",
        "      },\n",
        "       timeout_seconds=200):\n",
        "  max_attempts = 5\n",
        "\n",
        "  response = client.completions.create(\n",
        "                  model='gpt-3.5-turbo-instruct',\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  logprobs=logprobs,\n",
        "                  logit_bias=logit_bias,\n",
        "                  stop=list(stop_seq) if stop_seq is not None else None,\n",
        "              )\n",
        "\n",
        "#   for _ in range(max_attempts):\n",
        "#       try:\n",
        "#           with timeout(seconds=timeout_seconds):\n",
        "#               response = client.completions.create(\n",
        "#                   model='text-davinci-003',\n",
        "#                   prompt=prompt,\n",
        "#                   max_tokens=max_tokens,\n",
        "#                   temperature=temperature,\n",
        "#                   logprobs=logprobs,\n",
        "#                   logit_bias=logit_bias,\n",
        "#                   stop=list(stop_seq) if stop_seq is not None else None,\n",
        "#               )\n",
        "#           break\n",
        "#       except:\n",
        "#           print('Timeout, retrying...')\n",
        "#           pass\n",
        "  return response, response.choices[0].text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLq1cyarUFs3"
      },
      "source": [
        "## **Specify the instruction**\n",
        "Consider a setting where there can be a counter with three objects on top it (figure below). There are also a top drawer and a bottom drawer under the counter. There is a set of landfill, recycling, and compost bins next to the counter (not shown).\n",
        "\n",
        "<img src=\"https://robot-help.github.io/img/sample-mobile-manipulation.png\" height=\"200px\">\n",
        "\n",
        "The possible task instruction, for example, can be \"pick up the apple\", \"put the apple in the drawer\" (unclear about the choice of drawer), and \"dispose of the apple\".\n",
        "\n",
        "Besides the apple, orange, and Sprite shown in the image, we have also calibrated the LLM to perform tasks with these objects: bottled water, bottled tea, orange soda, RedBull, Coke, Pepsi, rice chips, jalapeno chips, kettle chips, multigrain chips, energy bar, dirty sponge with food residue, clean sponge, metal bowl, plastic bowl.\n",
        "\n",
        "Now you can specify the task instruction and also the three objects present on the countertop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "un9GDoSUilg9"
      },
      "outputs": [],
      "source": [
        "instruction = \"Put the bottled water in the bin.\" #@param {type:\"string\"}\n",
        "scene_objects = \"energy bar, bottled water, rice chips\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lgsoIZ0voJg"
      },
      "source": [
        "## **Access the LLM uncertainty**\n",
        "Next, we would like to see how uncertain the LLM is about the correct action to take in this scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "cellView": "form",
        "id": "9L0iTMBgsPtm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====== Prompt for generating possible options ======\n",
            "\n",
            "We: You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a bottom one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
            "\n",
            "We: On the counter, there is an orange soda, a Pepsi, and an apple.\n",
            "We: Put that drink in the top drawer.\n",
            "You:\n",
            "A) open the top drawer and put the orange soda in it\n",
            "B) open the bottom drawer and put the Pepsi in it\n",
            "C) open the bottom drawer and put the orange soda in it\n",
            "D) open the top drawer and put the Pepsi in it\n",
            "\n",
            "We: On the counter, there is an energy bar, a banana, and a microwave.\n",
            "We: Put the snack next to the microwave.\n",
            "You:\n",
            "A) pick up the energy bar and put it next to the microwave\n",
            "B) pick up the banana and put it next to the energy bar\n",
            "C) pick up the banana and put it next to the microwave\n",
            "D) pick up the energy bar and put it next to the banana\n",
            "\n",
            "We: On the counter, there is a Coke, a Sprite, and a sponge.\n",
            "We: Can you dispose of the can? It should have expired.\n",
            "You:\n",
            "A) pick up the sponge and put it in the landfill bin\n",
            "B) pick up the Coke and put it in the recycling bin\n",
            "C) pick up the Sprite and put it in the recycling bin\n",
            "D) pick up the Coke and put it in the landfill bin\n",
            "\n",
            "We: On the counter, there is a bottled water, a bag of jalapeno chips, and a bag of rice chips.\n",
            "We: I would like a bag of chips.\n",
            "You:\n",
            "A) pick up the bottled water\n",
            "B) pick up the jalapeno chips\n",
            "C) pick up the kettle chips\n",
            "D) pick up the rice chips\n",
            "\n",
            "We: On the counter, there is energy bar, bottled water, rice chips\n",
            "We: Put the bottled water in the bin.\n",
            "You:\n",
            "\n",
            "====== Generated options ======\n",
            "A) an option not listed here\n",
            "B) pick up the bottled water and put it back on the counter\n",
            "C) pick up the bottled water and put it in the compost bin\n",
            "D) pick up the bottled water and put it in the recycling bin\n",
            "E) pick up the bottled water and put it in the landfill bin\n"
          ]
        }
      ],
      "source": [
        "#@markdown First, we prompt the LLM to generate possible options with few-shot prompting\n",
        "demo_mc_gen_prompt = \"\"\"\n",
        "We: You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a bottom one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
        "\n",
        "We: On the counter, there is an orange soda, a Pepsi, and an apple.\n",
        "We: Put that drink in the top drawer.\n",
        "You:\n",
        "A) open the top drawer and put the orange soda in it\n",
        "B) open the bottom drawer and put the Pepsi in it\n",
        "C) open the bottom drawer and put the orange soda in it\n",
        "D) open the top drawer and put the Pepsi in it\n",
        "\n",
        "We: On the counter, there is an energy bar, a banana, and a microwave.\n",
        "We: Put the snack next to the microwave.\n",
        "You:\n",
        "A) pick up the energy bar and put it next to the microwave\n",
        "B) pick up the banana and put it next to the energy bar\n",
        "C) pick up the banana and put it next to the microwave\n",
        "D) pick up the energy bar and put it next to the banana\n",
        "\n",
        "We: On the counter, there is a Coke, a Sprite, and a sponge.\n",
        "We: Can you dispose of the can? It should have expired.\n",
        "You:\n",
        "A) pick up the sponge and put it in the landfill bin\n",
        "B) pick up the Coke and put it in the recycling bin\n",
        "C) pick up the Sprite and put it in the recycling bin\n",
        "D) pick up the Coke and put it in the landfill bin\n",
        "\n",
        "We: On the counter, there is a bottled water, a bag of jalapeno chips, and a bag of rice chips.\n",
        "We: I would like a bag of chips.\n",
        "You:\n",
        "A) pick up the bottled water\n",
        "B) pick up the jalapeno chips\n",
        "C) pick up the kettle chips\n",
        "D) pick up the rice chips\n",
        "\n",
        "We: On the counter, there is {scene_objects}\n",
        "We: {task}\n",
        "You:\n",
        "\"\"\"\n",
        "\n",
        "# Check if there are some repeated options or ill-positioned questions with fewer options\n",
        "# Add one option to add some stochastity\n",
        "def process_mc_raw(mc_raw, add_mc='an option not listed here'):\n",
        "  mc_all = mc_raw.split('\\n')\n",
        "\n",
        "  mc_processed_all = []\n",
        "  for mc in mc_all:\n",
        "      mc = mc.strip()\n",
        "\n",
        "      # skip nonsense\n",
        "      if len(mc) < 5 or mc[0] not in [\n",
        "          'a', 'b', 'c', 'd', 'A', 'B', 'C', 'D', '1', '2', '3', '4'\n",
        "      ]:\n",
        "          continue\n",
        "      mc = mc[2:]  # remove a), b), ...\n",
        "      mc = mc.strip().lower().split('.')[0]\n",
        "      mc_processed_all.append(mc)\n",
        "  if len(mc_processed_all) < 4:\n",
        "      raise 'Cannot extract four options from the raw output.'\n",
        "\n",
        "  # Check if any repeated option - use do nothing as substitue\n",
        "  mc_processed_all = list(set(mc_processed_all))\n",
        "  if len(mc_processed_all) < 4:\n",
        "      num_need = 4 - len(mc_processed_all)\n",
        "      for _ in range(num_need):\n",
        "          mc_processed_all.append('do nothing')\n",
        "  prefix_all = ['A) ', 'B) ', 'C) ', 'D) ']\n",
        "  if add_mc is not None:\n",
        "      mc_processed_all.append(add_mc)\n",
        "      prefix_all.append('E) ')\n",
        "  np.random.shuffle(mc_processed_all)\n",
        "\n",
        "  # get full string\n",
        "  mc_prompt = ''\n",
        "  for mc_ind, (prefix, mc) in enumerate(zip(prefix_all, mc_processed_all)):\n",
        "      mc_prompt += prefix + mc\n",
        "      if mc_ind < len(mc_processed_all) - 1:\n",
        "          mc_prompt += '\\n'\n",
        "  add_mc_prefix = prefix_all[mc_processed_all.index(add_mc)][0]\n",
        "  return mc_prompt, mc_processed_all, add_mc_prefix\n",
        "\n",
        "# Describe the scene following some formats\n",
        "demo_mc_gen_prompt = demo_mc_gen_prompt.replace('{task}', instruction)\n",
        "demo_mc_gen_prompt = demo_mc_gen_prompt.replace('{scene_objects}', scene_objects)\n",
        "\n",
        "# Generate multiple choices\n",
        "_, demo_mc_gen_raw = lm(demo_mc_gen_prompt, stop_seq=['We:'], logit_bias={})\n",
        "demo_mc_gen_raw = demo_mc_gen_raw.strip()\n",
        "demo_mc_gen_full, demo_mc_gen_all, demo_add_mc_prefix = process_mc_raw(demo_mc_gen_raw)\n",
        "\n",
        "print('====== Prompt for generating possible options ======')\n",
        "print(demo_mc_gen_prompt)\n",
        "\n",
        "print('====== Generated options ======')\n",
        "print(demo_mc_gen_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "form",
        "id": "mDlojk5zv0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logprobs(text_offset=[639], token_logprobs=[-0.039441045], tokens=[' D'], top_logprobs=[{' D': -0.039441045, ' B': -3.6786013, ' A': -5.0042086, ' E': -5.3881044, ' C': -6.149457}])\n",
            "Logprobs(text_offset=[639], token_logprobs=[-0.039441045], tokens=[' D'], top_logprobs=[{' D': -0.039441045, ' B': -3.6786013, ' A': -5.0042086, ' E': -5.3881044, ' C': -6.149457}])\n",
            "====== Prompt for scoring options ======\n",
            "You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a bottom one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
            "\n",
            "We: On the counter, there is energy bar, bottled water, rice chips\n",
            "We: Put the bottled water in the bin.\n",
            "You:\n",
            "A) an option not listed here\n",
            "B) pick up the bottled water and put it back on the counter\n",
            "C) pick up the bottled water and put it in the compost bin\n",
            "D) pick up the bottled water and put it in the recycling bin\n",
            "E) pick up the bottled water and put it in the landfill bin\n",
            "We: Which option is correct? Answer with a single letter.\n",
            "You:\n",
            "\n",
            "====== Raw log probabilities for each option ======\n",
            "Option: D \t log prob: -0.039441045\n",
            "Option: B \t log prob: -3.6786013\n",
            "Option: A \t log prob: -5.0042086\n",
            "Option: E \t log prob: -5.3881044\n",
            "Option: C \t log prob: -6.149457\n"
          ]
        }
      ],
      "source": [
        "#@markdown Then we evaluate the probabilities of the LLM predicting each option (A/B/C/D/E)\n",
        "\n",
        "# get the part of the current scenario from the previous prompt\n",
        "demo_cur_scenario_prompt = demo_mc_gen_prompt.split('\\n\\n')[-1].strip()\n",
        "\n",
        "# get new prompt\n",
        "demo_mc_score_background_prompt = \"\"\"\n",
        "You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a bottom one. There is also a landfill bin, a recycling bin, and a compost bin.\n",
        "\"\"\".strip()\n",
        "demo_mc_score_prompt = demo_mc_score_background_prompt + '\\n\\n' + demo_cur_scenario_prompt + '\\n' + demo_mc_gen_full\n",
        "demo_mc_score_prompt += \"\\nWe: Which option is correct? Answer with a single letter.\"\n",
        "demo_mc_score_prompt += \"\\nYou:\"\n",
        "\n",
        "# scoring\n",
        "mc_score_response, _ = lm(demo_mc_score_prompt, max_tokens=1, logprobs=5)\n",
        "top_logprobs_full = mc_score_response.choices[0].logprobs.top_logprobs[0]\n",
        "print(mc_score_response.choices[0].logprobs)\n",
        "print(mc_score_response.choices[0].logprobs)\n",
        "top_tokens = [token.strip() for token in top_logprobs_full.keys()]\n",
        "top_logprobs = [value for value in top_logprobs_full.values()]\n",
        "\n",
        "print('====== Prompt for scoring options ======')\n",
        "print(demo_mc_score_prompt)\n",
        "\n",
        "print('\\n====== Raw log probabilities for each option ======')\n",
        "for token, logprob in zip(top_tokens, top_logprobs):\n",
        "  print('Option:', token, '\\t', 'log prob:', logprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pryBm3sxFTh"
      },
      "source": [
        "## **Construct prediction set**\n",
        "With the probabilities from the LLM, we can construct the prediction set now. From calibration, we have determined the threshold to be 0.072 with a target success level of 0.8. This means the calibration set includes all options with softmax score higher than 0.072. Conformal prediction provides guarantee that the correct action is included in the set with 80% probability!\n",
        "\n",
        "When the set has more than one option, we deem the LLM is uncertain about the correct option and **triggers human help**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-oaU8ZXUwkh0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Softmax scores: [0.24863874 0.23796227 0.23347186 0.15818168 0.12174546]\n",
            "Prediction set: ['out', 'ex', 'od', ');', 'ul']\n",
            "Help needed!\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# Intentionally choose a threshold and only select the option above this threshold with softmax. If there are more than one option, then ask for human help\n",
        "qhat = 0.928\n",
        "\n",
        "# get prediction set\n",
        "def temperature_scaling(logits, temperature):\n",
        "    logits = np.array(logits)\n",
        "    logits /= temperature\n",
        "\n",
        "    # apply softmax\n",
        "    logits -= logits.max()\n",
        "    logits = logits - np.log(np.sum(np.exp(logits)))\n",
        "    smx = np.exp(logits)\n",
        "    return smx\n",
        "mc_smx_all = temperature_scaling(top_logprobs, temperature=5)\n",
        "\n",
        "# include all options with score >= 1-qhat\n",
        "prediction_set = [\n",
        "          token for token_ind, token in enumerate(top_tokens)\n",
        "          if mc_smx_all[token_ind] >= 1 - qhat\n",
        "      ]\n",
        "\n",
        "# print\n",
        "print('Softmax scores:', mc_smx_all)\n",
        "print('Prediction set:', prediction_set)\n",
        "if len(prediction_set) != 1:\n",
        "  print('Help needed!')\n",
        "else:\n",
        "  print('No help needed!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AkmZkTv6WW7s"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
